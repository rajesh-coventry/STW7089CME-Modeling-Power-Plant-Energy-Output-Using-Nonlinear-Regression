{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3e3aa",
   "metadata": {},
   "source": [
    "# **Simulation Based Learning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db128b",
   "metadata": {},
   "source": [
    "**Simulation** in machine learning is when we create a **virtual environment** that mimics the real world. This virtual environment is used to **train** and **test** machine learning models without needing real-world data or real-world actions.\n",
    "\n",
    "Imagine you’re building a robot to play soccer. Instead of making the robot play hundreds of real games (which takes time, energy, and money), you can create a **simulated soccer field on a computer**. The robot learns to play by practicing in the simulation.\n",
    "\n",
    "Sometimes in machine learning, collecting real data is:\n",
    "* Too **`expensive`**\n",
    "* Too **`dangerous`**\n",
    "* Too **`slow`**\n",
    "* Too **`rare`**\n",
    "\n",
    "So instead of relying on **`real-world data`**, we:\n",
    "1. Build a **`simulated environment`**.\n",
    "2. Let the model **`learn, make mistakes, and improve`** in that virtual world.\n",
    "3. Later, we may test or fine-tune it with real data.\n",
    "\n",
    "### **Simulation vs Model-Based Learning:**\n",
    "\n",
    "| Aspect      | Simulation                                                                      | Model-Based Learning                                                                                |\n",
    "| ----------- | ------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n",
    "| What is it? | A **virtual world** where the model learns by interacting with the environment. | A method where the model **learns a mathematical model** of the environment and then plans actions. |\n",
    "| Example     | A racing car game where AI learns to drive.                                     | An AI learning how cars move by building equations and predicting outcomes.                         |\n",
    "| Data Need   | No need for real-world data initially; the simulator provides the experience.   | Needs real or accurate data to learn the model.                                                     |\n",
    "| Flexibility | Easy to try different situations (weather, terrain, etc.).                      | Harder to test rare or dangerous events.                                                            |\n",
    "\n",
    "### **Why Use Simulation Instead of Model-Based Learning?**\n",
    "\n",
    "Because **real-world environments** can be:\n",
    "\n",
    "* **`Hard to model perfectly`** (too complex or unknown physics).\n",
    "* **`Risky`** (self-driving cars learning by crashing? Not safe).\n",
    "* **`Slow`** (waiting years to see the effects of a new drug? Too long).\n",
    "\n",
    "Simulation lets us **`experiment safely`, `quickly`, and `cheaply`**.\n",
    "\n",
    "\n",
    "**Summary:**\n",
    "* **Simulation** means teaching a model in a computer-made world that acts like the real world.\n",
    "* We use it when the real world is too dangerous, expensive, or hard to collect data from.\n",
    "* It's a powerful **alternative to model-based learning**, especially when it's hard to model everything mathematically.\n",
    "* Simulations allow faster, safer learning and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42313ab",
   "metadata": {},
   "source": [
    "------\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec718e24",
   "metadata": {},
   "source": [
    "### **Simulation-based Statistical Machine Learning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d97e5",
   "metadata": {},
   "source": [
    "In statistical modeling, simulation refers to creating artificial data or behavior by mimicking a real-world process, usually by using `random sampling` and a model that approximates reality.\n",
    "\n",
    "**Simulation-based approaches involve:**\n",
    "\n",
    "- Generating synthetic data from a model (forward simulation)\n",
    "\n",
    "- Repeating this process many times\n",
    "\n",
    "- Using the results to infer or learn something (e.g., `estimate parameters`, `test hypotheses`)\n",
    "\n",
    "Imagine we don’t know how exactly the data was generated — you only have a `black-box simulator` (like a function that takes in parameters and produces fake data). But you still want to learn about the parameters that would make the simulated data match the real data.\n",
    "\n",
    "For this; instead of solving a formula (which you may not have), you do this:\n",
    "\n",
    "1. Guess a parameter (e.g., from a `uniform distribution`).\n",
    "\n",
    "2. Simulate fake data using this guess.\n",
    "\n",
    "3. Compare the fake data to your real data.\n",
    "\n",
    "4. Keep the parameter if the fake data looks like real data.\n",
    "\n",
    "5. Do this many times, and you'll get a collection of good guesses → This is your posterior distribution.\n",
    "\n",
    "That’s a simulation-based inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd08f1",
   "metadata": {},
   "source": [
    "#### **Why Use Statistical Simulation instead of Model-Based Solution?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed418d",
   "metadata": {},
   "source": [
    "If you can use `Model Based Approach`, you should — it's efficient and reliable. \n",
    "\n",
    "But in real-world cases:\n",
    "1. Model may be too complex: For example, `non-linear`, `non-Gaussian`, or `involving physics simulations` or something that `can't be expressed in a mathemetical form` or `very difficult/complex to formulate the relation`\n",
    "\n",
    "2. Likelihood may not be available: For example,we `can't write down a formula` for how data depends on parameters.\n",
    "\n",
    "3. Data comes from a simulator: ie. we simulate behavior (e.g., `in biology`, `economics`, `epidemiology`) — not model it analytically.\n",
    "\n",
    "4. We want full uncertainty, not just point estimates: Simulation gives us a distribution, not just `\"the best guess.\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db30c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "> **Example:**   \n",
    "> Think of it like trying to find the `right combination on a safe`:     \n",
    "> \n",
    "> One approach is like having the manual: we know how the lock works, so we compute the combination. This is Model-Based Approach.\n",
    "> \n",
    "> Simulation-based inference is like `guessing the possible combinations`, trying them, and keeping the ones that open the safe — even though we don’t know how the mechanism inside works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa8bdb",
   "metadata": {},
   "source": [
    "#### **Head-to-Head:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5da09",
   "metadata": {},
   "source": [
    "| Feature                                | Traditional ML (e.g., Linear Regression) | Simulation-Based Learning   |\n",
    "| -------------------------------------- | ---------------------------------------- | --------------------------- |\n",
    "| Uses likelihood                        | Yes                                      | No                          |\n",
    "| Closed-form / gradient descent         | Yes                                      | No                          |\n",
    "| Uses simulator                         | No                                       | Yes                         |\n",
    "| Point estimate or distribution?        | Point estimate                           | Posterior distribution      |\n",
    "| Suitable for complex/black-box models? | No                                       | Yes                         |\n",
    "| Example method                         | Least Squares, GD                        | ABC, MCMC, Particle Filters |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22251ae6",
   "metadata": {},
   "source": [
    "-----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c87d9",
   "metadata": {},
   "source": [
    "### **Flowchart:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d2d9d",
   "metadata": {},
   "source": [
    "**Following Diagram shows some most common simulation based learning approachs/methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fe824",
   "metadata": {},
   "source": [
    "```\n",
    "        Simulation-Based Learning:            \n",
    "│\n",
    "├── (1) Approximate Bayesian Computation (ABC):\n",
    "│   ├── Rejection ABC\n",
    "│   ├── ABC-MCMC (Markov Chain Monte Carlo)\n",
    "│   └── ABC-SMC (Sequential Monte Carlo)\n",
    "│\n",
    "├── (2) Markov Chain Monte Carlo (MCMC):\n",
    "│   ├── Metropolis-Hastings\n",
    "│   └── Gibbs Sampling\n",
    "│\n",
    "├── (3) Sequential Monte Carlo (SMC):\n",
    "│   ├── Particle Filters\n",
    "│   └── SMC for Bayesian Inference\n",
    "│\n",
    "├── (4) Likelihood-Free Inference:\n",
    "│   ├── Synthetic Likelihood\n",
    "│   └── Density Ratio Estimation\n",
    "│\n",
    "└── (5) Other Simulation-Based Methods:\n",
    "    ├── Variational Bayesian Approaches (with simulated data)\n",
    "    └── Simulation-Based Optimization (e.g., Evolutionary Algorithms)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b471ae",
   "metadata": {},
   "source": [
    "1. **$ABC$ (Approximate Bayesian Computation)**: `Avoids likelihood entirely`; `compares simulated vs observed data`.\n",
    "\n",
    "2. **$MCMC$ (Markov Chain Monte Carlo)**: Samples from the posterior using a Markov chain; requires likelihood, but still simulation-based.\n",
    "\n",
    "3. **$SMC$ (Sequential Monte Carlo)**: Tracks a population of particles through time; used in dynamic models and time-series.\n",
    "\n",
    "4. **Likelihood-Free Inference**: Techniques where we can’t write down the likelihood but still estimate parameters.\n",
    "\n",
    "5. **Other Methods**: Includes any optimization or inference technique relying on simulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db37299",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d87bb6",
   "metadata": {},
   "source": [
    "### **Very Fundamental Concepts:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c05c5a",
   "metadata": {},
   "source": [
    "##### **1. Traditional Approach (e.g., Regression):**\n",
    "\n",
    "- You look at data, assume a mathematical form (like a line: $y = mx + c$), and define a loss function (e.g., `mean squared error`).\n",
    "\n",
    "- Then you find the best parameters by `minimizing that loss function` — either using a formula (`closed-form`) or by using `optimization` (like `gradient descent`).\n",
    "\n",
    "- You need to know or assume the relationship (linearity, etc.) between inputs and outputs.\n",
    "\n",
    "- This is called a `model-driven approach` — you drive the model by defining its shape and logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d555fbf",
   "metadata": {},
   "source": [
    "##### **2. Simulation-Based Approach (like ABC or MCMC):**\n",
    "\n",
    "- You have data, but you `can’t` (or `don’t want to`) write a formula for how it was generated.\n",
    "\n",
    "- Instead, you say: `“Let me guess parameters and use a simulator to generate fake data from them.”`\n",
    "\n",
    "- You compare fake data to the real data — if they match closely, the guessed parameters are likely to be good.\n",
    "\n",
    "- After many guesses, the collection of good ones gives you the posterior distribution — showing which parameters are plausible.\n",
    "\n",
    "- This is a data-driven or simulator-driven approach — you rely on simulations instead of analytical formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74d36f",
   "metadata": {},
   "source": [
    "##### **3. Posterior Distribution:**\n",
    "\n",
    "In simulation-based learning (especially in Bayesian methods like `ABC`): You’re not looking for just one best parameter. You want to know what range of parameters are possible, and how probable each is. That’s called the posterior distribution.\n",
    "\n",
    "**To get the exact idea of Posterior Distribution lets take an example:**\n",
    "\n",
    "Suppose I have very huge and complex dataset which contains millions of rows and thousands of colums. I have no clues on how the different variables are related to each other and it seems like it is very difficult or like impossible to form a mathematical relation that can relate these variables. So, I decide to use simulation based learning.\n",
    "\n",
    "Now, based on some simulation approach(like; ABC), I do repeaetd simulation experiments say 100,000 times by starting with some random parameter values ($(θ₁, θ₂, θ₃, ......)$ ← think of these as random guesses) and then generate fake data samples based on those parameters. On each simulation experiment we generate fake dataset. If I store the parameter values used in each simulation experiment in a tupple (.......) then there would be 100,000 such tuples which contains the parameter values used in each simulation experiment. After each simulation, I also compare the simulated data to the real data. Out of 100,000 simulations, only 500 simulations result in data that is `\"close enough\"` to the real data. These 500 \"accepted\" parameter tuples are the ones that can generate the data well, so they are `believable` or `plausible`. The distribution of these parameters that can generate data colse enough to the real data is called the `posterior distribution`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a6223",
   "metadata": {},
   "source": [
    "##### **Let's Construct the Posterior:**\n",
    "\n",
    "Suppose we have two parameters that we want to estimate:\n",
    "* `θ₁`: say, intercept\n",
    "* `θ₂`: say, slope\n",
    "\n",
    "Let’s say the 50 accepted parameter tuples (Parameter sets that closely match the observed data) look like this:\n",
    "\n",
    "```\n",
    "(1.0, 2.5)\n",
    "(1.1, 2.4)\n",
    "(0.9, 2.6)\n",
    "(1.0, 2.5)\n",
    "(1.2, 2.3)\n",
    ".........\n",
    "(1.1, 2.4)\n",
    "```\n",
    "\n",
    "These 50 tuples are the **`approximate posterior samples`**.\n",
    "\n",
    "Now:  \n",
    "##### 1. **Marginal Posterior Distributions:**\n",
    "\n",
    "* If we take all the `θ₁` values from the 50 samples then, this gives us the **`marginal posterior of θ₁`**\n",
    "\n",
    "* If we take all the `θ₂` values then, this gives us the **`marginal posterior of θ₂`**\n",
    "\n",
    "Now, we can:\n",
    "\n",
    "  1. Plot a `histogram` or `KDE` (smooth curve) of these values. \n",
    "  2. It will show you **`which values appear more often`**, i.e., which parameter values are **`more likely`** under the posterior.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "θ₁ (Intercept):\n",
    "  0.9 → 3 times\n",
    "  1.0 → 10 times\n",
    "  1.1 → 15 times\n",
    "  1.2 → 8 times\n",
    "→ So 1.1 is the most plausible value of θ₁\n",
    "\n",
    "θ₂ (Slope):\n",
    "  2.3 → 4 times\n",
    "  2.4 → 12 times\n",
    "  2.5 → 18 times\n",
    "  2.6 → 6 times\n",
    "→ So 2.5 is the most plausible value of θ₂\n",
    "```\n",
    "\n",
    "##### 2. **Joint Posterior Distribution:**\n",
    "\n",
    "We also have 50 **(θ₁, θ₂)** pairs.\n",
    "If we plot them on a 2D scatter plot or use a contour heatmap, the **`density of points`** in different areas tells us:\n",
    "\n",
    "  * What **combinations** of `(θ₁, θ₂)` are more likely\n",
    "  * Whether there’s a relationship between them (e.g., higher θ₁ means lower θ₂)\n",
    "\n",
    "This is our **joint posterior distribution** of `θ₁` and `θ₂`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137b179",
   "metadata": {},
   "source": [
    "\n",
    "| **`Term:`**                   | **`Meaning:`**                                                                            |\n",
    "| ---------------------- | ---------------------------------------------------------------------------------- |\n",
    "| **Prior**              | What you believe about parameters before seeing data (in ABC: your random guesses) |\n",
    "| **Likelihood**         | (Skipped in ABC) – probability of data given parameters                            |\n",
    "| **Posterior**          | What you believe about parameters **after** seeing how well they explain the data  |\n",
    "| **Posterior Samples**  | The subset of parameter guesses that produced good simulations                     |\n",
    "| **Marginal Posterior** | Distribution of each parameter independently (from accepted samples)               |\n",
    "| **Joint Posterior**    | Distribution over the combinations of parameters (from accepted pairs)             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31cdab",
   "metadata": {},
   "source": [
    "----\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb2dde",
   "metadata": {},
   "source": [
    "## **Approximate Bayesian Computation (ABC):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca362b4",
   "metadata": {},
   "source": [
    "#### **1. Bayes Theorem:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45671e",
   "metadata": {},
   "source": [
    "#### **2. What is Bayesian Inference?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72dd8f",
   "metadata": {},
   "source": [
    "#### **3. What is Approximate Bayesian Computation (ABC)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ae3fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c931fca",
   "metadata": {},
   "source": [
    "#### **4. What is Rejection ABC?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb6358",
   "metadata": {},
   "source": [
    "#### **5. Why Use ABC in Machine Learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63faa821",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
